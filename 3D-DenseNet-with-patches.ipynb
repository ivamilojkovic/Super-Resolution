{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# SETUP FOR DRIVE ENVIRONMENT ","metadata":{"id":"T3WM_DBMYk9a"}},{"cell_type":"code","source":"# Define the paths\ndataset_path = '../input/neuroengineering-project/Data/Data'\nmodel_path = '../input/neuroengineering-project/Data/Model'\noutput_path = '..output/kaggle/working'","metadata":{"id":"_N3rclVMtVa3","execution":{"iopub.status.busy":"2021-12-11T15:35:40.255531Z","iopub.execute_input":"2021-12-11T15:35:40.256004Z","iopub.status.idle":"2021-12-11T15:35:40.260209Z","shell.execute_reply.started":"2021-12-11T15:35:40.255959Z","shell.execute_reply":"2021-12-11T15:35:40.259288Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# MODULES TO BE IMPORTED","metadata":{"id":"21xlDGWfYpsG"}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport gc\nimport pickle\nimport math\nfrom random import shuffle\n\nimport nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_addons as tfa","metadata":{"id":"W7rdyVP4Rgyg","execution":{"iopub.status.busy":"2021-12-11T15:35:40.261827Z","iopub.execute_input":"2021-12-11T15:35:40.264857Z","iopub.status.idle":"2021-12-11T15:35:40.273726Z","shell.execute_reply.started":"2021-12-11T15:35:40.264821Z","shell.execute_reply":"2021-12-11T15:35:40.272879Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# CONSTANTS DEFINITION","metadata":{"id":"puQ4aEnNYwQ5"}},{"cell_type":"code","source":"# Unzip the files Model.zip and Data.zip\n#!unzip 'Data.zip'\n#!unzip 'Model.zip'\n\n# FOLDER TO LOAD DATA FROM\nDATA_PATH = dataset_path\nMODEL_PATH = model_path\n\n# SETUP\n# Volume size\nN_ROWS_VOLUME           = 128\nN_COLUMNS_VOLUME        = 128\nN_SLICES_VOLUME         = 64\nNOISE                   = 0.0001 # comment this line if your input volume don't require noise\n\n# Label size\nN_ROWS_LABEL            = 256\nN_COLUMNS_LABEL         = 256\nN_SLICES_LABEL          = 64\n\n# Patch sizes\nIN_PATCH_SIZE           = (16, 16, 16)\nOUT_PATCH_SIZE          = (32, 32, 16)\n\n# Type\nVOLUME_TYPE       = 'nii'\n\n# Use this if your input volume require noise\nVOLUME_TEMPLATE = \"{}/VolumeCT_%s_{}_{}_{}_n{}.{}\".format(\n    DATA_PATH,\n    N_ROWS_VOLUME,\n    N_COLUMNS_VOLUME,\n    N_SLICES_VOLUME,\n    str(NOISE),\n    VOLUME_TYPE\n    )\n\n# Use this if your input volume don't require noise\n#VOLUME_TEMPLATE = \"{}/VolumeCT_%s_{}_{}_{}.{}\".format(\n#    DATA_PATH,\n#    N_ROWS_VOLUME,\n#    N_COLUMNS_VOLUME,\n#    N_SLICES_VOLUME,\n#    VOLUME_TYPE\n#    )\n\nLABEL_TEMPLATE = \"{}/VolumeCT_%s_{}_{}_{}.{}\".format(\n    DATA_PATH,\n    N_ROWS_LABEL,\n    N_COLUMNS_LABEL,\n    N_SLICES_LABEL,\n    VOLUME_TYPE\n    )\n\n# DATA\n# Number of cases\nOVERALL_NUMBER_OF_CASES             = 58\n# TRAINING-VALIDATION-TEST PERCENTAGES\nTRAINING_PERC_CASES                 = 0.80\nVALIDATION_PERC_CASES               = 0.10\nTEST_PERC_CASES                     = 1 - TRAINING_PERC_CASES - VALIDATION_PERC_CASES\n\n# Model ID\nModelID                             = 'DensNet_2' \n\n# Maximum nuber of epochs\nMAX_EPOCHS                          = 100\n# Size for batch normalization\nBATCH_SIZE                          = 4\n# Learning Rate\nLEARNING_RATE                       = 0.001","metadata":{"id":"-nb5_4DmUZB8","execution":{"iopub.status.busy":"2021-12-11T15:35:40.274909Z","iopub.execute_input":"2021-12-11T15:35:40.275127Z","iopub.status.idle":"2021-12-11T15:35:40.288461Z","shell.execute_reply.started":"2021-12-11T15:35:40.275097Z","shell.execute_reply":"2021-12-11T15:35:40.287623Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# PATCHING AND MERGING","metadata":{"id":"F9zTOPTV-fu5"}},{"cell_type":"code","source":"# Patching grid -> list contains locations of patch centers\n\ndef make_patch_grid(patch_size, N_ROWS_VOLUME, N_COLUMNS_VOLUME, N_SLICES_VOLUME, overlap_bool=False, overlap = 1/2):\n    dim_patch = patch_size\n    if overlap_bool is False:\n        overlaps = (0, 0, 0)\n        center_dist = tuple(s//2 for s in dim_patch) \n        num_patch_dim1 = N_ROWS_VOLUME//dim_patch[0]\n        num_patch_dim2 = N_COLUMNS_VOLUME//dim_patch[1]\n        num_patch_dim3 = N_SLICES_VOLUME//dim_patch[2]\n        \n        patches=[]\n        for i in range(num_patch_dim1):\n            for j in range(num_patch_dim2):\n                for k in range(num_patch_dim3):    \n                    patch=(i*dim_patch[0]+center_dist[0], \n                           j*dim_patch[1]+center_dist[1], \n                           k*dim_patch[2]+center_dist[2])\n                    patches.append(patch)   \n    else:\n        # For example the overlap is 1/4 of the patch size     \n        overlaps = tuple(int(o*overlap) for o in dim_patch)\n        center_dist = tuple(d-o for d,o in zip(dim_patch, overlaps))\n        num_patch_dim1 = (N_ROWS_VOLUME-dim_patch[0])//center_dist[0] + 1\n        num_patch_dim2 = (N_COLUMNS_VOLUME-dim_patch[1])//center_dist[1] + 1\n        num_patch_dim3 = (N_SLICES_VOLUME-dim_patch[2])//center_dist[2] + 1\n        \n        patches=[]\n        for i in range(num_patch_dim1):\n            for j in range(num_patch_dim2):\n                for k in range(num_patch_dim3):    \n                    patch=((i+1)*dim_patch[0]//2+center_dist[0]-overlaps[0], \n                          (j+1)*dim_patch[1]//2+center_dist[1]-overlaps[1], \n                          (k+1)*dim_patch[2]//2+center_dist[2]-overlaps[2])\n                    patches.append(patch)\n\n    num_patches = len(patches)\n\n    return patches\n\ninput_patches = make_patch_grid(IN_PATCH_SIZE , \n                                N_ROWS_VOLUME, \n                                N_COLUMNS_VOLUME, \n                                N_SLICES_VOLUME,\n                                overlap_bool = False)\n\noutput_patches = make_patch_grid(OUT_PATCH_SIZE , \n                                 N_ROWS_LABEL, \n                                 N_COLUMNS_LABEL, \n                                 N_SLICES_LABEL,\n                                 overlap_bool = False)\n\nprint(len(input_patches))\nprint(len(output_patches))\n","metadata":{"id":"84ChcQEW-eCr","outputId":"3d2abd44-27df-474a-bf43-d81b509ba93e","execution":{"iopub.status.busy":"2021-12-11T15:35:40.290274Z","iopub.execute_input":"2021-12-11T15:35:40.290532Z","iopub.status.idle":"2021-12-11T15:35:40.307327Z","shell.execute_reply.started":"2021-12-11T15:35:40.290508Z","shell.execute_reply":"2021-12-11T15:35:40.306483Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def create_patches(image, patch_list, patch_size):\n    patches = []\n    step = tuple(s//2 for s in patch_size)\n    for p in patch_list:\n        patches.append(image[int(p[0])-step[0]:int(p[0])+step[0],\n                             int(p[1])-step[1]:int(p[1])+step[1],\n                             int(p[2])-step[2]:int(p[2])+step[2]])\n    return patches\n\n\ndef create_3D_image(patches, patch_size, image_size, patch_list, inout, overlap_bool=False, overlap = 1/2):\n    dim_patch = patch_size\n    image = np.zeros(image_size)\n    \n    if overlap_bool==False:\n        step = tuple(int(s//2) for s in patch_size)\n        for patch, patch_pos in enumerate(patch_list):\n            x = int(patch_pos[0])\n            y = int(patch_pos[1])\n            z = int(patch_pos[2])\n            if inout==True:\n                image[x-step[0]:x+step[0],y-step[1]:y+step[1],z-step[2]:z+step[2]]=patches[patch][:,:,:,0]\n            else:\n                image[x-step[0]:x+step[0],y-step[1]:y+step[1],z-step[2]:z+step[2]]=patches[patch]\n    else:\n        overlaps_list = []\n        overlaps = tuple(int(o*overlap) for o in dim_patch)\n        center_dist = tuple(d-o for d,o in zip(dim_patch, overlaps))\n        for i, patch_pos in enumerate(patch_list[0:-1]):\n            patch_curr = patch_pos\n            x_curr = int(patch_curr[0])\n            y_curr = int(patch_curr[1])\n            z_curr = int(patch_curr[2])\n            \n            patch_next = patch_list[i+1]\n            x_next = int(patch_next[0])\n            y_next = int(patch_next[1])\n            z_next = int(patch_next[2])\n            \n            if i == 0:\n                image[x_curr-overlaps[0]:x_curr, \n                      y_curr-overlaps[1]:y_curr,\n                      z_curr-overlaps[2]:z_curr] = patches[i][0:dim_patch[0]//2,0:dim_patch[1]//2, 0:dim_patch[2]//2]\n\n                overlap_part = patches[i][dim_patch[0]//2:,dim_patch[1]//2:, dim_patch[2]//2:]\n                overlap_part += patches[i+1][0:dim_patch[0]//2,0:dim_patch[1]//2, 0:dim_patch[2]//2]\n                overlap_part /= 2\n\n                image[x_curr:x_curr+overlaps[0], \n                      y_curr:y_curr+overlaps[1],\n                      z_curr:z_curr+overlaps[2]] = overlap_part\n            else:\n                overlap_part = patches[i][dim_patch[0]//2:, dim_patch[1]//2:, dim_patch[2]//2:]\n                overlap_part += patches[i+1][0:dim_patch[0]//2, 0:dim_patch[1]//2, 0:dim_patch[2]//2]\n                overlap_part /= 2\n\n                \n                image[x_curr-overlaps[0]:x_curr, \n                      y_curr-overlaps[1]:y_curr,\n                      z_curr-overlaps[2]:z_curr] = overlap_part\n                \n                image[x_curr:x_curr+overlaps[0], \n                      y_curr:y_curr+overlaps[1],\n                      z_curr:z_curr+overlaps[2]] = patches[i][dim_patch[0]//2:,dim_patch[1]//2:, dim_patch[2]//2:]\n\n    return image ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:35:40.309658Z","iopub.execute_input":"2021-12-11T15:35:40.309924Z","iopub.status.idle":"2021-12-11T15:35:40.332922Z","shell.execute_reply.started":"2021-12-11T15:35:40.309891Z","shell.execute_reply":"2021-12-11T15:35:40.332019Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocesing & Augmentation","metadata":{}},{"cell_type":"markdown","source":"## Removing mainly black patches","metadata":{}},{"cell_type":"code","source":"def remove_black_patches(patches):\n    num_voxels = len(patches[0].flatten())\n    non_black_patches = []\n    non_black_idx = []\n    for i, patch in enumerate(patches):\n        num_black_voxels = np.sum(patch<0.1)\n        if num_black_voxels<num_voxels//5*4:\n            non_black_patches.append(patch)\n            non_black_idx.append(i)\n        \n    return non_black_patches, non_black_idx     ","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:35:40.388423Z","iopub.execute_input":"2021-12-11T15:35:40.388764Z","iopub.status.idle":"2021-12-11T15:35:40.394352Z","shell.execute_reply.started":"2021-12-11T15:35:40.388735Z","shell.execute_reply":"2021-12-11T15:35:40.393563Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# DATA LOADING","metadata":{"id":"8jg2IUsMY3dd"}},{"cell_type":"code","source":"# Read available data\nAVAILABLE_NUMBER_OF_CASES = 0\ntry:\n    del trainVolumes\n    del trainLabels\n    del validationVolumes\n    del validationLabels\n    del testVolumes\n    del testLabels\nexcept:\n    pass\ngc.collect()\nvolumes_list = []\nlabels_list = []\n\nfor index_case in range(1, OVERALL_NUMBER_OF_CASES+1):\n    case_id = \"{:0>3}\".format(index_case)\n    volume_path = VOLUME_TEMPLATE % (case_id)\n    label_path = LABEL_TEMPLATE % (case_id)\n    if (os.path.exists(volume_path) and os.path.exists(label_path)):\n        AVAILABLE_NUMBER_OF_CASES += 1\n        volumes_list.append(volume_path)\n        labels_list.append(label_path)\n    else:\n        print(\"Not found\")\n        print(volume_path)\n        print(label_path)\n\n# SPLIT TRAINING AND VALIDATION SETS\nTRAINING_NUMBER_OF_CASES      = int(AVAILABLE_NUMBER_OF_CASES * TRAINING_PERC_CASES) * len(input_patches);\nVALIDATION_NUMBER_OF_CASES    = int(AVAILABLE_NUMBER_OF_CASES * VALIDATION_PERC_CASES) * len(input_patches);\nTEST_NUMBER_OF_CASES          = AVAILABLE_NUMBER_OF_CASES*len(input_patches) - TRAINING_NUMBER_OF_CASES - VALIDATION_NUMBER_OF_CASES;\nprint(\"Number of cases for training: \" + str(TRAINING_NUMBER_OF_CASES))\nprint(\"Number of cases for validation: \" + str(VALIDATION_NUMBER_OF_CASES))\nprint(\"Number of cases for testing: \" + str(TEST_NUMBER_OF_CASES))\n\n# Training set\ntrainVolumes = np.empty((TRAINING_NUMBER_OF_CASES, IN_PATCH_SIZE[0], IN_PATCH_SIZE[1], IN_PATCH_SIZE[2])) \ntrainLabels = np.empty((TRAINING_NUMBER_OF_CASES, OUT_PATCH_SIZE[0], OUT_PATCH_SIZE[1], IN_PATCH_SIZE[2]))  \n# Validation set\nvalidationVolumes = np.empty((VALIDATION_NUMBER_OF_CASES, IN_PATCH_SIZE[0], IN_PATCH_SIZE[1], IN_PATCH_SIZE[2])) \nvalidationLabels = np.empty((VALIDATION_NUMBER_OF_CASES, OUT_PATCH_SIZE[0], OUT_PATCH_SIZE[1], IN_PATCH_SIZE[2]))  \n# Training set\ntestVolumes = np.empty((TEST_NUMBER_OF_CASES, IN_PATCH_SIZE[0], IN_PATCH_SIZE[1], IN_PATCH_SIZE[2])) \ntestLabels = np.empty((TEST_NUMBER_OF_CASES, OUT_PATCH_SIZE[0], OUT_PATCH_SIZE[1], IN_PATCH_SIZE[2]))  \n\n# Grid for patches\ngrid_volumes = make_patch_grid((16,16,16), N_ROWS_VOLUME, N_COLUMNS_VOLUME, N_SLICES_VOLUME, overlap_bool=False, overlap = 1/2)\ngrid_labels = make_patch_grid((32,32,16), N_ROWS_LABEL, N_COLUMNS_LABEL, N_SLICES_LABEL, overlap_bool=False, overlap = 1/2)\nprint('Number of patches in one image: ', len(grid_volumes))\n\ncount           = 0\ncountTraining   = 0\ncountValidation = 0\ncountTest       = 0\nm=1\nfor volume, label in zip(volumes_list, labels_list):\n    if countTraining < TRAINING_NUMBER_OF_CASES:\n        # get the refs to training set\n        volumes = trainVolumes\n        labels  = trainLabels\n        index = countTraining\n        countTraining += len(input_patches)\n    elif countValidation < VALIDATION_NUMBER_OF_CASES:\n        volumes = validationVolumes\n        labels  = validationLabels\n        index = countValidation\n        countValidation += len(input_patches)\n    else:\n        # get the refs to validation set\n        volumes = testVolumes\n        labels  = testLabels\n        index = countTest\n        countTest += 1*len(input_patches)\n    \n    # Loading label -> getting patches \n    temp = nib.load(label) \n    temp = temp.get_fdata()\n    temp = np.asarray(temp)\n    patches = create_patches(temp, grid_labels, OUT_PATCH_SIZE )\n    labels[index:index+len(patches), :, :, :] = patches\n\n    # Loading inputs -> getting patches \n    temp = nib.load(volume)\n    temp = temp.get_fdata()\n    temp = np.asarray(temp)\n    if m==1:\n        image_temp = temp\n        m+=1\n    patches = create_patches(temp, grid_volumes, IN_PATCH_SIZE )\n    volumes[index:index+len(patches), :, :, :] = patches\n\n\n# Shuffle the dataset\n\n    \ntrainVolumes = trainVolumes.reshape(trainVolumes.shape + (1,)) # necessary to give it as input to model  \nvalidationVolumes = validationVolumes.reshape(validationVolumes.shape + (1,)) # necessary to give it as input to model  \ntestVolumes = testVolumes.reshape(testVolumes.shape + (1,)) # necessary to give it as input to model  \n\nremove_black = False\nif remove_black==True:\n    # Remove black patches\n    train_patches = trainVolumes[1:-1,:,:,:,0]\n    trainVolumes_non_black, idx_vol = remove_black_patches(train_patches)\n    trainLabels = np.array(trainLabels[idx_vol,:,:,:])\n\n    validation_patches = validationVolumes[1:-1,:,:,:,0]\n    validationVolumes_non_black, idx_vol = remove_black_patches(validation_patches)\n    validationLabels = np.array(validationLabels[idx_vol,:,:,:])\n  \n    trainVolumes = np.array(trainVolumes_non_black) \n    trainVolumes = trainVolumes.reshape(trainVolumes.shape + (1,)) # necessary to give it as input to model\n    validationVolumes = np.array(validationVolumes_non_black)\n    validationVolumes = validationVolumes.reshape(validationVolumes.shape + (1,)) # necessary to give it as input to model  \n\n    print('-----------------------------------------------------------')\n    print(\"Number of cases for training after removing black patches: \" + str(trainVolumes.shape[0]))\n    print(\"Number of cases for validation after removing black patches: \" + str(validationVolumes.shape[0]))\n    print(\"Number of cases for testing after removing black patches: \" + str(TEST_NUMBER_OF_CASES))\n","metadata":{"id":"FeCq6XGpqcxZ","outputId":"0dc6e43e-cddc-4b98-c64e-bbdaa11e7330","execution":{"iopub.status.busy":"2021-12-11T15:35:40.400418Z","iopub.execute_input":"2021-12-11T15:35:40.400826Z","iopub.status.idle":"2021-12-11T15:36:01.165443Z","shell.execute_reply.started":"2021-12-11T15:35:40.400794Z","shell.execute_reply":"2021-12-11T15:36:01.164643Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Check splitting and merging functions on one image\ninput_patches = make_patch_grid(IN_PATCH_SIZE , \n                                N_ROWS_VOLUME, \n                                N_COLUMNS_VOLUME, \n                                N_SLICES_VOLUME,\n                                overlap_bool = False)\n\nONE_IMAGE_N_PATCHES = len(input_patches)\nimage_patches = testVolumes[:ONE_IMAGE_N_PATCHES,:,:,:,:]\nimage_2 = create_3D_image(image_patches, IN_PATCH_SIZE , (128,128,64), input_patches, inout=True, overlap_bool=False, overlap = 1/2)\nprint(image_2.shape)\n\nimage_temp = testVolumes[:256,:,:,:,:]\nprint(image_temp.shape)\nimage_temp = create_3D_image(image_temp, IN_PATCH_SIZE , (128,128,64), input_patches, inout=True, overlap_bool=False, overlap = 1/2)\n\nfig, axis = plt.subplots(nrows=1, ncols=2, figsize=(10,18))\naxis[0].imshow(image_temp[:,:,32], cmap=plt.get_cmap('gray'))\naxis[0].set_title('Before Splitting Image')\naxis[1].imshow(image_2[:,:,32], cmap=plt.get_cmap('gray'))\naxis[1].set_title('After Merging Image')\nplt.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:36:01.167192Z","iopub.execute_input":"2021-12-11T15:36:01.167449Z","iopub.status.idle":"2021-12-11T15:36:01.762963Z","shell.execute_reply.started":"2021-12-11T15:36:01.167414Z","shell.execute_reply":"2021-12-11T15:36:01.762247Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# MODEL ARCHITECTURE","metadata":{"id":"-YtduEi3ZNAI"}},{"cell_type":"markdown","source":"## Define the class for padding = 'reflect'","metadata":{}},{"cell_type":"code","source":"#from keras.engine.topology import Layer\n#from keras.engine import InputSpec\n\n#class ReflectionPadding3D(Layer):\n#    def __init__(self, padding=(1, 1, 1), **kwargs):\n#        self.padding = tuple(padding)\n #       self.input_spec = [InputSpec(ndim=4)]\n#        super(ReflectionPadding3D, self).__init__(**kwargs)\n\n#    def get_output_shape_for(self, s):\n#        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n#        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3] + 2 * self.padding[2], s[4])\n\n #   def call(self, x, mask=None):\n #       w_pad,h_pad = self.padding\n #       return tf.pad(x, [[0,0,0], [h_pad,h_pad,h_pad], [w_pad,w_pad,w_pad], [0,0,0] ], 'REFLECT')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:46:31.517326Z","iopub.execute_input":"2021-12-11T15:46:31.517625Z","iopub.status.idle":"2021-12-11T15:46:31.521639Z","shell.execute_reply.started":"2021-12-11T15:46:31.517573Z","shell.execute_reply":"2021-12-11T15:46:31.520804Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Initialize input size\ninput_tensor = tf.keras.layers.Input(shape=(IN_PATCH_SIZE[0],\n                                            IN_PATCH_SIZE[1],\n                                            IN_PATCH_SIZE[2],\n                                            1))\n# Number of filters                                            \nk = 48 \n\n#--------------------------------------------------------------------------------------------\n#----------------------------Create Model----------------------------------------------------\n#--------------------------------------------------------------------------------------------\n\nconv1_out = tf.keras.layers.Conv3D(filters = 2*k, kernel_size=(3,3,3),\n                                   strides = (1,1,1), padding='same')(input_tensor)\n\nup6_1 = tf.keras.layers.UpSampling3D(size=(2,2,1))(conv1_out)\n\nprint('Output shape after conv1: {}'.format(conv1_out.shape))\nprint('Output upsamp shape after conv1: {}'.format(up6_1.shape))\n\n#----------------------------Block 1---------------------------------------------------------\n\nblock1_out = tf.keras.layers.LayerNormalization()(conv1_out)\n#block1_out = tfa.layers.SpectralNormalization()(conv1_out)\nblock1_out = tf.keras.layers.ELU()(block1_out)\nblock1_out = tf.keras.layers.Conv3D(filters = k, kernel_size=(3,3,3),\n                                    strides = (1,1,1), padding='same')(block1_out)\nup6_2 = tf.keras.layers.UpSampling3D(size=(2,2,1))(block1_out)\n\n#----------------------------Block 2---------------------------------------------------------\n\n#block2_out = tfa.layers.SpectralNormalization()(block1_out)\nblock2_out = tf.keras.layers.LayerNormalization()(block1_out)\nblock2_out = tf.keras.layers.ELU()(block2_out)\nblock2_out = tf.keras.layers.Conv3D(filters = k, kernel_size=(3,3,3),\n                                    strides = (1,1,1), padding='same')(block2_out)\nup6_3 = tf.keras.layers.UpSampling3D(size=(2,2,1))(block2_out)\nprint('Output shape after block2: {}'.format(block2_out.shape))     \n\n#----------------------------Block 3---------------------------------------------------------\nblock3_input = tf.keras.layers.Concatenate(axis=4)([block1_out, block2_out])\n\n#block3_out = tfa.layers.SpectralNormalization()(block3_input)\nblock3_out = tf.keras.layers.LayerNormalization()(block3_input)\nblock3_out = tf.keras.layers.ELU()(block3_out)\nblock3_out = tf.keras.layers.Conv3D(filters = k, kernel_size=(3,3,3),\n                                    strides = (1,1,1), padding='same')(block3_out)\nup6_4 = tf.keras.layers.UpSampling3D(size=(2,2,1))(block3_out)\nprint('Output shape after block3: {}'.format(block3_out.shape))     \n\n#----------------------------Block 4---------------------------------------------------------\n\nblock4_input = tf.keras.layers.Concatenate(axis=4)([block1_out, block2_out, block3_out])\n\n#block4_out = tfa.layers.SpectralNormalization()(block4_input)\nblock4_out = tf.keras.layers.LayerNormalization()(block4_input)\nblock4_out = tf.keras.layers.ELU()(block4_out)\nblock4_out = tf.keras.layers.Conv3D(filters = k, kernel_size=(3,3,3),\n                                    strides = (1,1,1), padding='same')(block4_out)\nup6_5 = tf.keras.layers.UpSampling3D(size=(2,2,1))(block4_out)\nprint('Output shape after block4: {}'.format(block4_out.shape))     \n\n#----------------------------Block 5---------------------------------------------------------\n\nblock5_input = tf.keras.layers.Concatenate(axis=4)([block1_out, block2_out, \n                                                    block3_out, block4_out])\n#block5_out = tfa.layers.SpectralNormalization()(block5_input)\nblock5_out = tf.keras.layers.LayerNormalization()(block5_input)\nblock5_out = tf.keras.layers.ELU()(block5_out)\nblock5_out = tf.keras.layers.Conv3D(filters = k, kernel_size=(3,3,3),\n                                    strides = (1,1,1), padding='same')(block5_out)\nup6_6 = tf.keras.layers.UpSampling3D(size=(2,2,1))(block5_out)\n\n# ----------------------------Output---------------------------------------------------------  \n\nlast_conv_input = tf.keras.layers.Concatenate(axis=4)([up6_6, up6_5, up6_4,\n                                                       up6_3, up6_2, up6_1])\nout = tf.keras.layers.Conv3D(filters = 1, kernel_size=(3,3,3),\n                             strides = (1,1,1), padding='same')(last_conv_input)\n\noutput_tensor = tf.keras.layers.Reshape((OUT_PATCH_SIZE[0],\n                                         OUT_PATCH_SIZE[1],\n                                         OUT_PATCH_SIZE[2],\n                                         1))(out)\n\nmy_model = tf.keras.Model(inputs = [input_tensor], \n                          outputs = [output_tensor])\nmy_model.summary()\ntf.keras.utils.plot_model(my_model)","metadata":{"id":"fXf57ERrKn-M","outputId":"ec30b06b-cf3e-4d88-9e91-84eaa84355fd","execution":{"iopub.status.busy":"2021-12-11T15:40:05.583098Z","iopub.execute_input":"2021-12-11T15:40:05.583606Z","iopub.status.idle":"2021-12-11T15:40:09.264993Z","shell.execute_reply.started":"2021-12-11T15:40:05.583549Z","shell.execute_reply":"2021-12-11T15:40:09.261070Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# PSNR & SSIM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import backend as K\nfrom tensorflow.image import psnr\n\ndef PSNR(y_true, y_pred):\n    max_pixel = 1.0\n    #psnr = (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1))))\n    return psnr(y_true, y_pred, max_pixel)\n\ndef SSIM(y_true, y_pred):\n    return -tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0, filter_size = 5))\n\ndef MAE_and_SSIM_loss(y_true, y_pred):\n    mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n    ssim = SSIM(y_true, y_pred)\n    return abs(mae-ssim)/2\n\ndef PSNR_and_MAE_loss(y_true, y_pred):\n    \n    # Since PSNR can be (-inf, +inf) we need to scale it to [0, 1]\n    psnr_limit = tf.constant(80.0)\n    psnr_val = PSNR(y_true, y_pred)  \n    if psnr_val > psnr_limit:\n        psnr_val = psnr_limit\n    if psnr_val < -1*psnr_limit:\n        psnr_val = psnr_limit\n    psnr_scaled = (psnr_val + psnr_limit)/(2 * psnr_limit)\n    \n    mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n    mae = K.cast(mae, 'float32')\n    \n    result = (mae + psnr_scaled)/2 \n    return tf.constant(result, dtype=tf.float32)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-02T21:24:47.053269Z","iopub.execute_input":"2021-12-02T21:24:47.053768Z","iopub.status.idle":"2021-12-02T21:24:47.06738Z","shell.execute_reply.started":"2021-12-02T21:24:47.053726Z","shell.execute_reply":"2021-12-02T21:24:47.06678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LOSS FUNCTION","metadata":{"id":"eeFA-PT0Y_Dq"}},{"cell_type":"markdown","source":"Useful links for loss functions:\n* https://towardsdatascience.com/deep-learning-image-enhancement-insights-on-loss-function-engineering-f57ccbb585d7#:~:text=Peak%20signal%2Dto%2Dnoise%20ratio%20definition%20(PSNR)%20is,created%20by%20compressing%20the%20image.\n* https://stackoverflow.com/questions/49404309/how-does-keras-handle-multiple-losses","metadata":{"id":"ZO-JQNIBdQ1E"}},{"cell_type":"code","source":"my_loss = [tf.keras.losses.MeanSquaredError(), SSIM]\n#my_loss = MAE_and_SSIM_loss","metadata":{"id":"eKdIVnsIZBoe","execution":{"iopub.status.busy":"2021-12-02T21:24:47.06991Z","iopub.execute_input":"2021-12-02T21:24:47.070577Z","iopub.status.idle":"2021-12-02T21:24:47.081788Z","shell.execute_reply.started":"2021-12-02T21:24:47.070517Z","shell.execute_reply":"2021-12-02T21:24:47.081082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CUSTOM METRICS","metadata":{"id":"FsACQUMTZG_V"}},{"cell_type":"markdown","source":"Choose the metrics for you model from tf.keras.metrics or write your own custom metrics here","metadata":{"id":"8P8nLBvPdcs9"}},{"cell_type":"code","source":"my_metrics = [tf.keras.metrics.MeanSquaredError(), PSNR, SSIM, tf.keras.metrics.MeanAbsoluteError()]","metadata":{"id":"Y67wXq97fMpk","execution":{"iopub.status.busy":"2021-12-02T21:24:47.083212Z","iopub.execute_input":"2021-12-02T21:24:47.083502Z","iopub.status.idle":"2021-12-02T21:24:47.102738Z","shell.execute_reply.started":"2021-12-02T21:24:47.083464Z","shell.execute_reply":"2021-12-02T21:24:47.102054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CUSTOM CALLBACKS","metadata":{"id":"tFfa4CK3dGln"}},{"cell_type":"markdown","source":"Choose the callbacks of interest (e.g. Tensorboard or ModelCheckpoint) and append them to my_callbacks_list","metadata":{"id":"RgM2-ztTdvC8"}},{"cell_type":"markdown","source":"**EarlyStopping** callback is used very often. This allows us to monitor our metrics, and stop model training when it stops improving. For example, assume that you want to stop training if the accuracy is not improving by 0.05; you can use this callback to do so. This is useful in preventing overfitting of a model.\n\n**ModelCheckpoint** callback allows us to save the model regularly during training. This is especially useful when training deep learning models which take a long time to train. This callback monitors the training and saves model checkpoints at regular intervals, based on the metric.\n\n\n","metadata":{"id":"6ZZcibOOwKDu"}},{"cell_type":"code","source":"from datetime import datetime\n\ndef make_callbacks(model_name):\n\n    exps_dir = os.path.join('experiments')\n    if not os.path.exists(exps_dir):\n        os.makedirs(exps_dir)\n\n    now = datetime.now().strftime('%b%d_%H-%M-%S')\n\n    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n    if not os.path.exists(exp_dir):\n        os.makedirs(exp_dir)\n\n    my_callbacks = []\n\n    # Early stopping callbacks ---------------------------------------------------\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                                 patience=10, \n                                                 restore_best_weights = True)\n    my_callbacks.append(es_callback)\n\n    # Checkpoints ----------------------------------------------------------------\n    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n    if not os.path.exists(ckpt_dir):\n        os.makedirs(ckpt_dir)\n\n    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(ckpt_dir, \n                                                    monitor='val_loss', \n                                                    save_best_only=False,\n                                                    save_weights_only=False, \n                                                    mode='auto', \n                                                    save_freq='epoch')\n    my_callbacks.append(ckpt_callback)\n\n    # Tensorboard ---------------------------------------------------------------- \n    tb_dir = os.path.join(exp_dir, 'tb_logs')\n    if not os.path.exists(tb_dir):\n        os.makedirs(tb_dir)\n\n    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, update_freq=1)\n    my_callbacks.append(tb_callback)\n\n    return my_callbacks\n\n","metadata":{"id":"DRRacvh3vHhB","execution":{"iopub.status.busy":"2021-12-02T21:24:47.104353Z","iopub.execute_input":"2021-12-02T21:24:47.10483Z","iopub.status.idle":"2021-12-02T21:24:47.117838Z","shell.execute_reply.started":"2021-12-02T21:24:47.104787Z","shell.execute_reply":"2021-12-02T21:24:47.116863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL TRAINING","metadata":{"id":"Bq3lBNz-fRRf"}},{"cell_type":"code","source":"# Set model optimizer\n# compiling model:\nmy_model.compile(\n    optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE),\n    loss      = my_loss,\n    loss_weights = [2,1],\n    metrics   = my_metrics \n    )\n\n# Create the folder for callbacks\nModelID = 'Model_3D_DensNet_Patches_'\nmy_callbacks = make_callbacks(model_name=ModelID)\n\n\n# Run Model Training\nmonitoring = my_model.fit(x = trainVolumes, \n                          y = trainLabels, \n                          batch_size = BATCH_SIZE,\n                          shuffle = True,\n                          epochs = MAX_EPOCHS, \n                          validation_data = (validationVolumes,\n                                             validationLabels),  \n                          callbacks = my_callbacks) ","metadata":{"id":"13GbuYIDxqLe","outputId":"0b386617-8b89-44b6-b3bb-09f37e3b4b4f","execution":{"iopub.status.busy":"2021-12-02T21:24:47.119578Z","iopub.execute_input":"2021-12-02T21:24:47.120059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the net\nmy_model.save(os.path.join(output_path,\n                           f\"model_{ModelID}.h5\"))","metadata":{"id":"13GbuYIDxqLe","outputId":"0b386617-8b89-44b6-b3bb-09f37e3b4b4f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL EVALUATION","metadata":{"id":"Ou5akZDKfT-I"}},{"cell_type":"code","source":"PLOT = True\nprediction = my_model.predict(testVolumes[:,:,:,:,0])\n\nprint(my_model.evaluate(x = testVolumes, y = testLabels))\n          \n# just visualizing slice by slice:\n#if PLOT:\n#    for case in range(len(testVolumes)):\n #       for i in range(0, N_SLICES_VOLUME):\n#            fig = plt.figure(figsize = [9, 3])\n#            plt.subplot(1, 3, 1)\n#            plt.imshow(testVolumes[case, :, :, i, 0], cmap = 'gray')\n#            plt.subplot(1, 3, 2)\n#            plt.imshow(testLabels[case, :, :, i], cmap = 'gray')\n#            plt.subplot(1, 3, 3)\n#            plt.imshow(prediction[case, :, :, i], cmap = 'gray')\n#            plt.show(fig)","metadata":{"id":"S3Lf8wB91fuL","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If you want to load a pre-trained model\n# Set this parameter 'True' only if you want to load another model, otherwise leave it 'False'\nLOAD = False                    \n#MODEL_NAME =       # The name of the model to load \n\nif LOAD is True:\n    model_to_load = os.path.join(output_path, f\"model_{ModelID}.h5\")\n    my_model = tf.keras.models.load_model(model_to_load, compile = False)\n\n    my_model.compile(\n        optimizer = keras.optimizers.Adam(learning_rate = custom_learning_rate_program()),\n        loss    = my_loss,\n        metrics = my_metrics,\n        )\n\n    print(\"Model loaded!\")","metadata":{"id":"9OVv7spC5vrR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MERGING Neural Network Outputs","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimage_idx = 1\nnum_patches = 256\npatch_depth = 16\n\n# Extract patches that make one image from the input and the output\ntestVol = testVolumes[:image_idx*num_patches,:,:,:,:]  # first 32 patches are the first input image \ntestLab = testLabels[:image_idx*num_patches,:,:,:]\npredVol = prediction[:image_idx*num_patches,:,:,0]     # first 32 patches are the first label image\n\n# Merge patches\nimage_in = create_3D_image(testVol, (16,16,16), (128,128,64), input_patches, inout=True)\nimage_out = create_3D_image(predVol, (32,32,16), (256,256,64), output_patches, inout= False)\nimage_true = create_3D_image(testLab, (32,32,16), (256,256,64), output_patches, inout= False)\n\nfig, axis = plt.subplots(nrows=1, ncols=3, figsize=(13,20))\naxis[0].imshow(image_in[:,:,32], cmap=plt.get_cmap('gray'))\naxis[0].set_title('Input Image')\naxis[1].imshow(image_out[:,:,32], cmap=plt.get_cmap('gray'))\naxis[1].set_title('Output Image')\naxis[2].imshow(image_true[:,:,32], cmap=plt.get_cmap('gray'))\naxis[2].set_title('True Image')\nplt.tight_layout()\n\n\nnow = datetime.now().strftime('%b%d_%H-%M-%S')\nplt.savefig('foo' + now + '.png')\n\n# Plotting the values \nfrom skimage.metrics import mean_squared_error, peak_signal_noise_ratio, structural_similarity\n\nmse_ = mean_squared_error(image_out,image_true)\npsnr_ = peak_signal_noise_ratio(image_out,image_true)\nssim_ = structural_similarity(image_out,image_true)\nprint('MSE: {}, PSNR: {}, SSIM: {}'.format(mse_,psnr_,ssim_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"_PGcW5PPy8CX"},"execution_count":null,"outputs":[]}]}